import random
import numpy as np

"""
å®ç°éšæœºæ¢¯åº¦ä¸‹é™ç®—æ³•çš„å‰é¦ˆç¥ç»ç½‘ç»œï¼Œé€šè¿‡åå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦
"""


class Network:

    def __init__(self, sizes):
        """
        åˆå§‹åŒ–ç¥ç»ç½‘ç»œï¼Œé€šè¿‡sizeså‚æ•°çš„å½¢çŠ¶åˆå§‹åŒ–å¤§å°ã€å±‚æ•°ï¼Œå¹¶éšæœºåˆå§‹åŒ–æƒé‡å’Œåç½®å€¼
        :param sizes: æ¯å±‚ç¥ç»ç½‘ç»œåŒ…å«ç¥ç»å…ƒçš„æ•°ç›®åˆ—è¡¨ï¼Œå¦‚[2,3,1]è¡¨ç¤ºè¾“å…¥å±‚æœ‰2ä¸ªç¥ç»å…ƒï¼Œç¬¬2å±‚æœ‰3ä¸ªç¥ç»å…ƒï¼Œç¬¬3å±‚æœ‰1ä¸ªç¥ç»å…ƒ
        """
        # å±‚æ•°
        self.num_layers = len(sizes)
        # å„å±‚ä¿¡æ¯
        self.sizes = sizes
        # éšæœºç”Ÿæˆå¯¹åº”æ•°é‡çš„åç½®å€¼ï¼Œç¬¬ä¸€å±‚ä¸ºè¾“å…¥ç¥ç»å…ƒï¼Œæ— éœ€åç½®å€¼è®¡ç®—ã€‚randn(i, 1)ç”Ÿæˆiè¡Œ1åˆ—ä¸ªæ ‡å‡†æ­£æ€åˆ†å¸ƒçš„éšæœºå€¼
        self.biases = [np.random.randn(i, 1) for i in sizes[1:]]
        # ç”Ÿæˆç¬¦åˆæ ‡å‡†æ­£æ€åˆ†å¸ƒçš„éšæœºåˆå§‹æƒé‡å€¼ã€‚å¦‚ç¬¬1å±‚æœ‰iä¸ªç¥ç»å…ƒã€ç¬¬2å±‚æœ‰jä¸ªç¥ç»å…ƒï¼Œåˆ™ä¸¤å±‚ä¹‹é—´éœ€è¦ç”Ÿæˆjè¡Œiåˆ—ä¸ªæƒé‡å€¼
        self.weights = [np.random.randn(j, i) for i, j in zip(sizes[:-1], sizes[1:])]

    def sigmoid(self, z):
        """
        æ¿€æ´»å‡½æ•°sigmoid: 1 / 1 + e^(-z)
        :param z: è®¡ç®—çš„æ•°å€¼
        :return: è®¡ç®—çš„ç»“æœ
        """
        return 1.0 / (1.0 + np.exp(-z))

    def sigmoid_prime(self, z):
        """
        è®¡ç®—sigmoidå‡½æ•°çš„å¯¼æ•°ï¼Œå¯è¯æ˜å¯¹äºf(x)=1 / 1 + e^(-z), fâ€˜ï¼ˆxï¼‰=f(x)(1-f(x))
        :param z: åŸå§‹æ•°å€¼
        :return: åŸå§‹æ•°å€¼çš„f'(z)
        """
        return self.sigmoid(z) * (1 - self.sigmoid(z))

    def feedforward(self, a):
        """
        è¿›è¡Œå‰é¦ˆè®¡ç®—ï¼Œå³ç”¨âˆ‘w.a+bè®¡ç®—é€å±‚è®¡ç®—æ¯ä¸€å±‚çš„è¾“å‡º
        :param a: ä¸Šä¸€å±‚ç¥ç»ç½‘ç»œçš„è¾“å‡ºï¼Œæœ¬å±‚çš„è¾“å…¥
        :return: è¾“å‡ºç»“æœï¼Œä»ä¿å­˜åœ¨aä¸­
        """
        for b, w in zip(self.biases, self.weights):
            # np.dotä¸ºå‘é‡çš„ç‚¹ä¹˜ï¼Œå³w.a+b
            a = self.sigmoid(np.dot(w, a) + b)
        return a

    def evaluate(self, test_data):
        """
        è¿”å›æµ‹è¯•è¾“å‡ºæ ·æœ¬ä¸­é¢„æµ‹æ­£ç¡®çš„æ•°ç›®
        :param test_data: æµ‹è¯•æ•°æ®
        :return: é¢„æµ‹æ­£ç¡®çš„æ•°é‡
        """
        # é¢„æµ‹çš„ç»“æœä¿å­˜åœ¨æœ€åä¸€å±‚ç¥ç»å…ƒä¸­ï¼Œç»“æœä¸ºå“ªä¸€ä¸ªï¼Œå“ªä¸€ä¸ªç¥ç»å…ƒçš„è¾“å‡ºå€¼å°±æœ€å¤§ã€‚é€šè¿‡np.argmaxå‡½æ•°æ‰¾å‡ºæœ€å¤§å€¼çš„ç´¢å¼•
        test_result = [(np.argmax(self.feedforward(x)), y) for x, y in test_data]
        # å¦‚æœæ‰¾åˆ°çš„ç´¢å¼•å’Œyä¸€æ ·ï¼Œè¯´æ˜é¢„æµ‹æ­£ç¡®ã€‚å°†x==yçš„å¸ƒå°”å€¼è½¬æ¢ä¸ºintå€¼ï¼Œint(True) = 1
        return sum(int(x == y) for x, y in test_result)

    def SGD(self, training_data, epochs, mini_batch_size, eta, test_data=None):
        """
        å°†æ•°æ®åˆ†æˆæ‰¹é‡{mini_batch_size}é€æ¬¡æ›´æ–°æƒé‡å’Œåç½®å€¼
        :param training_data: è®­ç»ƒæ•°æ®ï¼ŒåŒ…å«è¾“å…¥æ•°æ®x, è¾“å‡ºyã€‚ä»¥ï¼ˆx,yï¼‰çš„å½¢å¼
        :param epochs: è®­ç»ƒçš„è½®æ¬¡ï¼ˆéšæœºå–å®Œæ‰€æœ‰çš„æ•°æ®ä¸€æ¬¡ä¸ºä¸€è½®ï¼‰
        :param mini_batch_size: æ¯æ¬¡è¿›è¡Œéšæœºå–æ ·çš„å¤§å°
        :param eta: å­¦ä¹ ç‡Î·
        :param test_data: æµ‹è¯•æ•°æ®ï¼Œå¦‚æœ‰åˆ™ä¼šè¿›è¡ŒéªŒè¯
        :return: æ— 
        """
        # å°†è®­ç»ƒæ•°æ®è½¬æ¢ä¸ºåˆ—è¡¨ç»“æ„
        training_data = list(training_data)
        # å°†æµ‹è¯•æ•°æ®è½¬æ¢ä¸ºåˆ—è¡¨ç»“æ„
        test_data = list(test_data) if test_data else None
        # æµ‹è¯•æ•°æ®çš„æ•°é‡ï¼Œå…ˆè½¬æ¢ä¸ºåˆ—è¡¨ï¼Œå†å¾—åˆ°åˆ—è¡¨å…ƒç´ çš„ä¸ªæ•°
        n_test = len(test_data) if test_data else 0
        # è¾“å…¥ã€è¾“å‡ºæ•°æ®å¯¹æ•°ï¼Œä¸€ä¸ªè¾“å…¥x,ä¸€ä¸ªè¾“å‡ºyä¸ºä¸€å¯¹
        n = len(training_data)
        # è¿›è¡Œepochsè½®è®­ç»ƒ
        for j in range(epochs):
            # éšæœºæ‰“ä¹±è®­ç»ƒæ•°æ®ï¼Œä»æ­¤ç§æ–¹å¼å®ç°æ¯æ¬¡éšæœºå–æ ·mini_batch_sizeå¯¹æ•°æ®
            random.shuffle(training_data)
            # å°†æ•°æ®åˆ‡åˆ†æˆå¤§å°ä¸ºkçš„å—ï¼Œæ¯å—çš„å¤§å°ä¸ºk + mini_batch_size - k = mini_batch_size
            mini_batches = [training_data[k:k + mini_batch_size] for k in range(0, n, mini_batch_size)]
            # ä½¿ç”¨æœ¬è½®çš„æ‰€æœ‰å—é€æ¬¡æ›´æ–°ç¥ç»ç½‘ç»œçš„æƒé‡å’Œåç½®å€¼
            for mini_batch in mini_batches:
                self.update_mini_batch(mini_batch, eta)
            # å¦‚æœè®¾å®šäº†æµ‹è¯•æ•°æ®ï¼Œåˆ™ä½¿ç”¨æœ¬è½®è®­ç»ƒå¥½çš„ç¥ç»ç½‘ç»œé¢„æµ‹æ‰€æœ‰æµ‹è¯•æ ·æœ¬ï¼Œè¾“å‡ºè®¡ç®—é¢„æµ‹æ­£ç¡®çš„ä¸ªæ•°/æ€»æµ‹è¯•æ ·æœ¬æ•°
            if test_data:
                print(f"Epoch {j}: {self.evaluate(test_data)} / {n_test}")
            else:
                print(f"Epoch {j} completed.")

    def update_mini_batch(self, mini_batch, eta):
        """
        å¯¹ä¸€æ‰¹æ•°æ®åº”ç”¨æ¢¯åº¦ä¸‹é™å’Œåå‘ä¼ æ’­ç®—æ³•æ›´æ–°æ•´ä¸ªç¥ç»ç½‘ç»œçš„æƒé‡å’Œåç½®
        :param mini_batch: ç”±è‹¥å¹²ä¸ª(x,y)ç»„æˆçš„åˆ—è¡¨
        :param eta: å­¦ä¹ ç‡Î·
        :return: æ— 
        """
        # ç”¨np.zerosç”Ÿæˆåç½®å€¼ã€æƒé‡å¯¹åº”å½¢çŠ¶ï¼ˆå‡ è¡Œå‡ åˆ—ï¼‰çš„ç”¨0å¡«å……çš„åˆ—è¡¨,è®°å½•æ¢¯åº¦ä¿¡æ¯ï¼ˆå°çƒæ»šåŠ¨çš„æ–¹å‘ï¼‰ã€‚ç»“æ„å’Œweightsã€biasesä¸€æ ·
        nabla_b = [np.zeros(b.shape) for b in self.biases]
        nabla_w = [np.zeros(w.shape) for w in self.weights]

        for x, y in mini_batch:
            # é€šè¿‡åå‘ä¼ æ’­ï¼Œæ‰¾åˆ°w, bçš„æ¢¯åº¦
            delta_nabla_b, delta_nabla_W = self.backprop(x, y)
            # å°†æ¢¯åº¦ä¿¡æ¯æ›´æ–°åˆ°nabla_wï¼Œ nabla_b
            nabla_w = [nw + dnw for nw, dnw in zip(nabla_w, delta_nabla_W)]
            # æ›´æ–°æ‰€æœ‰çš„åç½®å€¼
            nabla_b = [nb + dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]
        # ç”¨w - Î· / m * æ¢¯åº¦ï¼ˆå¯¹æƒé‡çš„æ¢¯åº¦ï¼‰è®¡ç®—å‡ºæ›´æ–°ä¹‹åçš„æƒé‡å€¼
        self.weights = [w - (eta / len(mini_batch)) * nw for w, nw in zip(self.weights, nabla_w)]
        # ç”¨w - Î· / m * æ¢¯åº¦ï¼ˆå¯¹åç½®å€¼çš„æ¢¯åº¦ï¼‰è®¡ç®—å‡ºæ›´æ–°ä¹‹åçš„åç½®å€¼å€¼
        self.biases = [b - (eta / len(mini_batch)) * nb for b, nb in zip(self.biases, nabla_b)]

    def backprop(self, x, y):
        """
        åå‘ä¼ æ’­ç®—æ³•
        :param x: è¾“å…¥æ•°æ®
        :param y: è¾“å‡ºæ•°æ®
        :return: è¿”å›ä¸€ä¸ªå’Œweights, biasesç»“æ„ä¸€æ ·çš„æ¢¯åº¦æ•°æ®
        """
        # ç”¨np.zerosç”Ÿæˆåç½®å€¼ã€æƒé‡å¯¹åº”å½¢çŠ¶ï¼ˆå‡ è¡Œå‡ åˆ—ï¼‰çš„ç”¨0å¡«å……çš„åˆ—è¡¨ã€‚ç»“æ„å’Œweightsã€biasesä¸€æ ·
        nabla_b = [np.zeros(b.shape) for b in self.biases]
        nabla_w = [np.zeros(w.shape) for w in self.weights]
        # æœ¬æ¬¡æ¿€æ´»å‡½æ•°è®¡ç®—çš„ç»“æœï¼Œåˆå§‹åŒ–ä¸ºè¾“å…¥
        activation = x
        # ä¿å­˜ä¸ºæ‰€æœ‰æ¿€æ´»çš„ç»“æœ
        activations = [x]
        # ä¿å­˜æ‰€æœ‰çš„z,è¿ç®—å¼ä¸ºâˆ‘w.a+b
        zs = []
        for b, w in zip(self.biases, self.weights):
            # æœ¬å±‚çš„æ¿€æ´»å‰çš„ç»“æœï¼Œz = âˆ‘w.a+b
            z = np.dot(w, activation) + b
            zs.append(z)
            # è®¡ç®—ç»è¿‡æ¿€æ´»å‡½æ•°ä¹‹åçš„ç»“æœ
            activation = self.sigmoid(z)
            # ä¿å­˜æ‰€æœ‰æ¿€æ´»åçš„å€¼
            activations.append(activation)
        # åå‘ä¼ æ’­ï¼Œä»åå¾€å‰ï¼Œé€å±‚ä½¿ç”¨ã€‚åˆå§‹çš„è¯¯å·®é¡¹ç”±æŸå¤±å‡½æ•°æä¾›
        delta = self.cost_derivative(activations[-1], y) * self.sigmoid_prime(zs[-1])

        nabla_b[-1] = delta
        nabla_w[-1] = np.dot(delta, activations[-2].transpose())
        # ä»åå¾€å‰é€å±‚è®¡ç®—æƒé‡å’Œåç½®å€¼çš„åå¯¼æ•°ï¼Œ-2ä¸ºå€’æ•°ç¬¬2å±‚
        for l in range(2, self.num_layers):
            z = zs[-l]
            # è®¡ç®—å¯¼æ•°
            sp = self.sigmoid_prime(z)
            # -lå±‚çš„è¯¯å·®
            delta = np.dot(self.weights[-l + 1].transpose(), delta) * sp
            # -lå±‚çš„âˆ‡ğ‘¤å’Œâˆ‡ğ‘
            nabla_b[-l] = delta
            nabla_w[-l] = np.dot(delta, activations[-l - 1].transpose())

        return nabla_b, nabla_w

    def cost_derivative(self, output_activations, y):
        """
        å–å¾—æœ€ç»ˆè¾“å‡ºæ¿€æ´»å€¼çš„åå¯¼æ•°çš„å‘é‡ï¼Œå¯¹äºæŸå¤±å‡½æ•°(âˆ‘(a-y)^2) / 2çš„å¯¼æ•°ï¼Œä¸ºa-y
        :param output_activations: å®é™…çš„è¾“å‡ºå€¼
        :param y: çœŸå®çš„è¾“å‡ºå€¼
        :return: æŸå¤±å‡½æ•°çš„å¯¼æ•°
        """
        return output_activations - y
